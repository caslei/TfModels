# From the website: http://www.ctolib.com/topics-101544.html


#1、首先需要安装TensorFlow
git clone https://github.com/tensorflow/models

#2、其次添加clone的代码库路径，
import os
import sys

os.environ["CUDA_VISIBLE_DEVICES"] = '0'
sys.path.append("E:\\TfModels\\slim")

#3、接着下载VGG-16模型，用于图像分类与分割

from datasets import dataset_utils
import tensorflow as tf

url = "http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz"

#指定保存路径
chechpoints_dir = 'e:\\checkpoints'

if not tf.gfile.Exists(checkpoints_dir):
    tf.gfile.MakeDirs(checkpoints_dir)

dataset_utils.download_and_uncompress_tarball(url, checkpoints_dir)

# 执行结果如下：
>> Downloading vgg_16_2016_08_28.tar.gz 100.0%
    Successfully downloaded vgg_16_2016_08_28.tar.gz 513324920 bytes.



#--------------------------------------------------------------------
# 图像分类
#--------------------------------------------------------------------

from matplotlib import pyplot as plt

import numpy as np
import os
import tensorflow as tf

#urllib和urllib2在python3被统一到rullib中
from urllib.request import urlopen

from datasets import imagenet
from nets import vgg
from preprocessing import vgg_preprocessing

checkpoints_dir = 'e:\\checkpoints'

slim = tf.contrib.slim

# 网络模型的输入图像有默认的尺寸； 因此，我们需要先调整输入图片的尺寸
image_size = vgg.vgg_16.default_image_size

with tf.Graph().as_default():
	url = ("https://upload.wikimedia.org/wikipedia/commons/d/d9/First_Student_IC_school_bus_202076.jpg")

	# 连接网址，下载图片
	image_string = urlopen(url).read()

	# 将图片解码成jpeg格式
	image = tf.image.decode_jpeg(image_string, channels=3)

	# 对图片做缩放操作，保持长宽比例不变，裁剪得到图片中央的区域
	# 裁剪后的图片大小等于网络模型的默认尺寸
	processed_image = vgg_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)

	# 可以批量导入图像； 第一个维度指定每批图片的张数； 我们每次只导入一张图片
	processed_images = tf.expand_dims(processed_image, 0)

	# 创建模型，使用默认的arg scope参数
	# arg_scope是slim library的一个常用参数
	# 可以设置它指定网络层的参数，比如stride, padding 等等。
	with slim.arg_scope(vgg.vgg_arg_scope()):
		logits, _ = vgg.vgg_16(processed_images, num_classes=1000, is_training=False)

	# 我们在输出层使用softmax函数，使输出项是概率值
	probabilities = tf.nn.softmax(logits)

	# 创建一个函数，从checkpoint读入网络权值
	init_fn = slim.assign_from_checkpoint_fn( os.path.join(checkpoints_dir, 'vgg_16.ckpt'), slim.get_model_variables('vgg_16') )

	with tf.Session() as sess:
		# 加载权值
    	init_fn(sess)

    	# 图片经过缩放和裁剪，最终以numpy矩阵的格式传入网络模型
    	np_image, network_input, probabilities = sess.run([image, processed_image, probabilities])
    	probabilities = probabilities[0, 0:]
    	sorted_inds = [i[0] for i in sorted(enumerate(-probabilities), key=lambda x:x[1])]

	# 显示下载的图片
	plt.figure()
	plt.imshow(np_image.astype(np.uint8))
	plt.suptitle("Downloaded image", fontsize=14, fontweight='bold')
	plt.axis('off')
	plt.ion()
	plt.show()

	# 显示最终传入网络模型的图片
	# 图像的像素值做了[-1, 1]的归一化
	# to show the image.
	plt.figure()
	plt.imshow( network_input / (network_input.max() - network_input.min()) )
	plt.suptitle("Resized, Cropped and Mean-Centered input to network", fontsize=14, fontweight='bold')
	plt.axis('off')
	plt.ion()
	plt.show()

	names = imagenet.create_readable_names_for_imagenet_labels()
	for i in range(5):
		index = sorted_inds[i]
		# 打印top5的预测类别和相应的概率值。
		print('Probability %0.2f => [%s]' % (probabilities[index], names[index+1]))

	res = slim.get_model_variables()    



Probability 1.00 => [school bus]
Probability 0.00 => [minibus]
Probability 0.00 => [passenger car, coach, carriage]
Probability 0.00 => [trolleybus, trolley coach, trackless trolley]
Probability 0.00 => [cab, hack, taxi, taxicab]







#--------------------------------------------------------------------
# 图像标注与分割
#--------------------------------------------------------------------

from preprocessing import vgg_preprocessing
from urllib.request import urlopen

# 加载像素均值及相关函数
from preprocessing.vgg_preprocessing import (_mean_image_subtraction, _R_MEAN, _G_MEAN, _B_MEAN)

# 展现分割结果的函数，以不同的颜色区分各个类别
def discrete_matshow(data, labels_names=[], title=""):
    #获取离散化的色彩表
    cmap = plt.get_cmap('Paired', np.max(data)-np.min(data)+1)
    mat = plt.matshow(data, cmap=cmap, vmin = np.min(data)-.5, vmax = np.max(data)+.5)
    
    #在色彩表的整数刻度做记号
    cax = plt.colorbar(mat, ticks=np.arange(np.min(data),np.max(data)+1))

    # 添加类别的名称
    if labels_names:
        cax.ax.set_yticklabels(labels_names)

    if title:
        plt.suptitle(title, fontsize=14, fontweight='bold')


with tf.Graph().as_default():
    url = ("https://upload.wikimedia.org/wikipedia/commons/d/d9/First_Student_IC_school_bus_202076.jpg")

    image_string = urlopen(url).read()
    image = tf.image.decode_jpeg(image_string, channels=3)

    # 减去均值之前，将像素值转为32位浮点
    image_float = tf.to_float(image, name='ToFloat')

    # 每个像素减去像素的均值
    processed_image = _mean_image_subtraction(image_float, [_R_MEAN, _G_MEAN, _B_MEAN])

    input_image = tf.expand_dims(processed_image, 0)

    with slim.arg_scope(vgg.vgg_arg_scope()):
        # spatial_squeeze选项指定是否启用全卷积模式
        logits, _ = vgg.vgg_16(input_image, num_classes=1000, is_training=False, spatial_squeeze=False)

    # 得到每个像素点在所有1000个类别下的概率值，挑选出每个像素概率最大的类别
    # 严格说来，这并不是概率值，因为我们没有调用softmax函数
    # 但效果等同于softmax输出值最大的类别
    pred = tf.argmax(logits, dimension=3)

    init_fn = slim.assign_from_checkpoint_fn( os.path.join(checkpoints_dir, 'vgg_16.ckpt'), slim.get_model_variables('vgg_16') )

    with tf.Session() as sess:
        init_fn(sess)
        segmentation, np_image = sess.run([pred, image])

# 去除空的维度
segmentation = np.squeeze(segmentation)

unique_classes, relabeled_image = np.unique(segmentation, return_inverse=True)

segmentation_size = segmentation.shape

relabeled_image = relabeled_image.reshape(segmentation_size)

labels_names = []

for index, current_class_number in enumerate(unique_classes):
    labels_names.append(str(index) + ' ' + names[current_class_number+1])

discrete_matshow(data=relabeled_image, labels_names=labels_names, title="Segmentation")




##---------------------------------------------------------------------------------------------
## 以上两例都使用VGG-16模型对图像做分类和分割，也可以选用其它占用内存少的网络模型（如AlexNet）进行处理。
## 电脑配置不高的情况下，进了使用耗内存少的模型，这是比较方便验证算法有效性的。
##---------------------------------------------------------------------------------------------




#----------------------------------------
  break 和continue的中断功能，具有“就近原则”，即：只有其最近的循环有关，与其他循环没半毛钱关系

#------------------------------------------------
 python程序中，以逗号分隔的变量被默认为元组(tuple)



#------------------------------------------------
 import os
	import实际是将os.py的文件载入指定文件中，

 import matplotlib.pyplot as plt
 	表示将matplotlib文件夹下的pyplot.py载入指定文件中



from module import something

module是一个模块，说白了就是一个文件，比如datetime.py文件
something是模块中的具体对象，可以是函数，变量，或者类



类

类的概念在许多语言中出现，很容易理解。它将数据和操作进行封装，以便将来的复用。
模块

模块，在Python可理解为对应于一个文件。在创建了一个脚本文件后，定义了某些函数和变量。你在其他需要这些功能的文件中，导入这模块，就可重用这些函数和变量。一般用module_name.fun_name，和module_name.var_name进行使用。这样的语义用法使模块看起来很像类或者名字空间，可将module_name 理解为名字限定符。模块名就是文件名去掉.py后缀。

client.py

def func():
    print "hello world!"

 

main.py

import client
if __name__ == '__main__':
    print __name__
    client.func()
    print client.__name__
 

>>python main.py  ---> result:

__main__

hello world!

client

模块属性__name__，它的值由Python解释器设定。如果脚本文件是作为主程序调用，其值就设为__main__，如果是作为模块被其他文件导入，它的值就是其文件名。

每个模块都有自己的私有符号表，所有定义在模块里面的函数把它当做全局符号表使用。

模块可以导入其他的模块。通常将import语句放在模块的开头，被导入的模块名字放在导入它的模块的符号表中。
from module import names  可以直接从模块中导入名字到符号表，但模块名字不会被导入。
from module import *     可以把模块中的所有名字全部导入，除了那些以下划线开头的名字符号。不建议使用，不清楚导入了什么符号，有可能覆盖自己定义的东西
 
内建函数dir()可以查看模块定义了什么名字（包括变量名，模块名，函数名等）：dir(模块名)，没有参数时返回所有当前定义的名字
模块搜索路径
当导入一个模块时，解释器先在当前包中查找模块，若找不到，然后在内置的built-in模块中查找，找不到则按sys.path给定的路径找对应的模块文件(模块名.py)
sys.path的初始值来自于以下地方：
    包含脚本当前的路径，当前路径
    PYTHONPATH
    默认安装路径
sys.path初始化完成之后可以更改
 
编译过的Python文件: .pyc文件
    
 
built-in 模块

上面的例子中，当client被导入后，python解释器就在当前目录下寻找client.py的文件，然后再从环境变量PYTHONPATH寻找，如果这环境变量没有设定，也不要紧，解释器还会在安装预先设定的的一些目录寻找。这就是在导入下面这些标准模块，一切美好事情能发生的原因。

这些搜索目录可在运行时动态改变，比如将module1.py不放在当前目录，而放在一个冷僻的角落里。这里你就需要通过某种途径，如sys.path，来告知Python了。sys.path返回的是模块搜索列表，通过前后的输出对比和代码，应能理悟到如何增加新路径的方法了吧。非常简单，就是使用list的append()或insert()增加新的目录。

#module2.py
import sys
import os

print sys.path
workpath = os.path.dirname(os.path.abspath(sys.argv[0]))
sys.path.insert(0, os.path.join(workpath, 'modules'))
print sys.path

其他的要点

模块能像包含函数定义一样，可包含一些可执行语句。这些可执行语句通常用来进行模块的初始化工作。这些语句只在模块第一次被导入时被执行。这非常重要，有些人以为这些语句会多次导入多次执行，其实不然。

模块在被导入执行时，python解释器为加快程序的启动速度，会在与模块文件同一目录下生成.pyc文件。我们知道python是解释性的脚本语言，而.pyc是经过编译后的字节码，这一工作会自动完成，而无需程序员手动执行。
包

通常包总是一个目录，可以使用import导入包，或者from + import来导入包中的部分模块。包目录下为首的一个文件便是 __init__.py。然后是一些模块文件和子目录，假如子目录中也有 __init__.py 那么它就是这个包的子包了。

在创建许许多多模块后，我们可能希望将某些功能相近的文件组织在同一文件夹下，这里就需要运用包的概念了。包对应于文件夹，使用包的方式跟模块也类似，唯一需要注意的是，当文件夹当作包使用时，文件夹需要包含__init__.py文件，主要是为了避免将文件夹名当作普通的字符串。__init__.py的内容可以为空，一般用来进行包的某些初始化工作或者设置__all__值，__all__是在from package-name import *这语句使用的，全部导出定义过的模块。

 
可以从包中导入单独的模块。
1). import PackageA.SubPackageA.ModuleA,使用时必须用全路径名
2). 变种: from PackageA.SubPackageA import ModuleA, 可以直接使用模块名而不用加上包前缀。
3). 也可以直接导入模块中的函数或变量：from PackageA.SubPackageA.ModuleA import functionA
 
import语句语法：
1. 当使用from package import item时，item可以是package的子模块或子包，或是其他的定义在包中的名字（比如一个函数、类或变量）
   首先检查item是否定义在包中，不过没找到，就认为item是一个模块并尝试加载它，失败时会抛出一个ImportError异常。
2. 当使用import item.subitem.subsubitem语法时，最后一个item之前的item必须是包，最后一个item可以是一个模块或包，但不能是类、函数和变量
 
3. from pacakge import *
   如果包的__init__.py定义了一个名为__all__的列表变量，它包含的模块名字的列表将作为被导入的模块列表。
   如果没有定义__all__， 这条语句不会导入所有的package的子模块，它只保证包package被导入，然后导入定义在包中的所有名字。
 
python包是：
包是一个有层次的文件目录结构，它定义了由n个模块或n个子包组成的python应用程序执行环境。
通俗一点：包是一个包含__init__.py 文件的目录，该目录下一定得有这个__init__.py文件和其它模块或子包。
 
 
常见问题：

    引入某一特定路径下的模块
        使用sys.path.append(yourmodulepath)

    将一个路径加入到python系统路径下，避免每次通过代码指定路径
        利用系统环境变量 export PYTHONPATH=$PYTHONPATH:yourmodulepath，
        直接将这个路径链接到类似/Library/Python/2.7/site-packages目录下

    好的建议
        经常使用if __name__ == '__main__'，保证你写包既可以import又可以独立运行，用于test。
        多次import不会多次执行模块，只会执行一次。可以使用reload来强制运行模块，但不提倡。

包（package）

为了组织好模块，将多个模块分为一个包。包是python模块文件所在的目录，且该目录下必须存在__init__.py文件。常见的包结构如下：

package_a
├── __init__.py
├── module_a1.py
└── module_a2.py
package_b
├── __init__.py
├── module_b1.py
└── module_b2.py
main.py

    如果main.py想要引用packagea中的模块modulea1，可以使用:

from package_a import module_a1
import package_a.module_a1

    如果packagea中的modulea1需要引用packageb，那么默认情况下，python是找不到packageb。我们可以使用sys.path.append('../'),可以在packagea中的__init__.py添加这句话，然后该包下得所有module都添加* import __init_即可。




#--------------------------------------------
python中，一切数据均为对象，一切变量均是对数据的引用

熟用Python内置的三个函数：help(), type(), dir()



#--------------------------------------------
函数名称： tf.Graph.as_default()
返回值：返回一个上下文管理器，这个上下文管理器使用这个图作为默认的图

说明：如果你想在一个进程里创建多个图，可能会用到这个方法。
     为了方便，如果你没有显式创建一个图的话，系统提供了一个全局默认的图，
     默认把所有的操作都添加到全局默 认图中。使用这个方法的话（配合with关键词使用），
     可以只把with块里的操作添加到默认图中。默认图是当前线程的一个属性，
     如果你创建了一个新的线程，想使用全局默认图，必须显式调用这个方法。

示例：
    g = tf.Graph()    # 新建了一个图，将该图显示作为默认图 
    with g.as_default():
        c = tf.constant(5.0)  
        assert c.graph is g  

函数名称：tf.Graph.device(device_name_or_function)
返回值：返回一个上下文管理器，这个上下文管理器明确使用哪个设备
参数  ：可以是一个设备名称的字符串或者一个函数

示例:
    # 所有在上下文里构建的操作，都会放到gpu:0这个设备上来运行 
    with tf.Graph().device('/gpu:0'):  

    # 所有在上下文里构建的操作，将不会放到任何设备上  
    with tf.Graph().device(None):


函数名称：tf.Graph.control_dependencies(control_inputs)
返回值：返回一个上下文，这个上下文中明确了控制依赖
参数  ：一个操作或者张量的集合，这个操作或者张量必须被执行或者计算先于定义在上下文中的操作
说明  ：控制依赖可以被嵌套。
       可以通过传递None来清空控制依赖
       形成控制依赖的张量或者操作必须在返回的上下文里被定义

示例：
    1. 基础用法
    with g.control_dependencies([a, b, c]):  
        # `d` 和`e` 在 `a`, `b`, 和`c` 被执行之后运行  
        d = ...  
        e = ...  

    2.依赖的嵌套
    with g.control_dependencies([a, b]):  
        # 此处构建的操作在 `a` 和 `b`都被执行后才执行.  
            with g.control_dependencies([c, d]):  
                # 此处构建的操作在`a`, `b`, `c`, 和 `d`都被执行后才执行 

    3.清空控制依赖
    with g.control_dependencies([a, b]):  
        # 此处构建的操作在 `a` 和 `b`都被执行后才执行.  
        with g.control_dependencies(None):  
            # 此处构架的操作正常执行，不用等待a和b，因为依赖被清空.  
            with g.control_dependencies([c, d]):  
                # 此处构建的操作在 `c` 和 `d`执行之后执行，不用等待a和b

    4.形成控制依赖的张量必须在上下文里被定义
    # 错误  
    def my_func(pred, tensor):  
        t = tf.matmul(tensor, tensor)  
        with tf.control_dependencies([pred]):  
            # matmul操作在上下文外被创建，因此错误  
        return t  
      
    # 正确 
    def my_func(pred, tensor):  
        with tf.control_dependencies([pred]):  
        # matmul操作在上下文内被创建，因此正确  
        return tf.matmul(tensor, tensor)  

#--------------------------------------------
更多内容可参看网站: http://lib.csdn.net/article/machinelearning/39582



#--------------------------------------------
python assert断言的作用
assert断言是其布尔值必须为真的判定，如果发生异常就说明为假。用来测试表示式，其返回值为假，就会触发异常。

assert expression
下面做一些assert用法的语句供参考：
assert 1==1
assert 2+2==2*2
assert len(['my boy',12])<10
assert range(4)==[0,1,2,3]

如何为assert断言语句添加异常参数
assert的异常参数，其实就是在断言表达式后添加字符串信息，解释断言并更好的知道是哪里出了问题。
assert expression [, arguments]
assert 表达式 [, 参数]
assert len(lists) >=5,'列表元素个数小于5'
assert 2==1,'2不等于1'


#--------------------------------------------
python -c "import tensorflow as tf; help(tf.ones)"   >  tf.ones.txt

$ python -c "import os; import inspect; import tensorflow; print(os.path.dirname(inspect.getfile(tensorflow)))"  > dirname.txt

# 非常实用的管道符与帮助信息
#--------------------------------------------