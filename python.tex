% !Mode :: "Tex:UTF-8"




\documentclass{article}

%\usepackage{tables}
\usepackage{tabularx}

\usepackage{color, xcolor}

\usepackage{url}

\usepackage{./Mcode/mcode}




\input{PythonStyle.tex}








\begin{document}

\section{Built-in Functions}
The Python interpreter has a number of functions and types built into it that are always available. They are listed here in alphabetical order.

\begin{table}
\begin{tabular}{|l|l|l|l|l|}
\hline
abs()       & dict()        & help()        & min()     & setattr() \\
\hline
all()      & dir()         & hex()         & next()    & slice()   \\
\hline
any()       & divmod()      & id()          & object()  & sorted()  \\
\hline
ascii()     & enumerate()   & input()       & oct()     & staticmethod() \\
\hline
bin()       & eval()        & int()         & open()     & str()    \\
\hline
bool()      & exec()        & isinstance()  & ord()     & sum()     \\
\hline
bytearray() & filter()      & issubclass()  & pow()     & super()   \\
\hline
bytes()     & float()       & iter()        & print()   & tuple()   \\
\hline
callable()  & format()      & len()         & property() & type()   \\
\hline
chr()       & frozenset()   & list()        & range()   & vars()    \\
\hline
classmethod() & getattr()   & locals()      & repr()    & zip()     \\
\hline
compile()   & globals()     & map()         & reversed() & \_\_import\_\_() \\
\hline
complex()   & hasattr()     & max()         & round()   &  \\
\hline
delattr()   & hash()        & memoryview()  & set()     &  \\
\hline
\end{tabular}
\end{table}



\begin{table}
\begin{tabular}{|l|l|l|l|l|}
\hline
pass       & True        & False        & None     &  class \\
\hline
from      & import         & with         & def    & not   \\
\hline
if       & elseif      & else          & for  & is  \\
\hline
while     & raise   & in       & as     & and \\
\hline
or       & return        & yield         & lambda     & str()    \\
\hline
bool()      & exec()        & isinstance()  & ord()     & sum()     \\
\hline
bytearray() & filter()      & issubclass()  & pow()     & super()   \\
\hline
bytes()     & float()       & iter()        & print()   & tuple()   \\
\hline
callable()  & format()      & len()         & property() & type()   \\
\hline
chr()       & frozenset()   & list()        & range()   & vars()    \\
\hline
classmethod() & getattr()   & locals()      & repr()    & zip()     \\
\hline
compile()   & globals()     & map()         & reversed() & \_\_import\_\_() \\
\hline
complex()   & hasattr()     & max()         & round()   &  \\
\hline
delattr()   & hash()        & memoryview()  & set()     &  \\
\hline
\end{tabular}
\end{table}


\subsection{Functions parse}
\subsubsection*{abs(x)}
    Return the absolute value of a number. The argument may be an integer or a floating point number. If the argument is a complex number, its magnitude is returned.

all(iterable):
    Return True if all elements of the iterable are true (or if the iterable is empty).

any(iterable):
    Return True if any element of the iterable is true. If the iterable is empty, return False.

ascii(object):
    As repr(), return a string containing a printable representation of an object, but escape the non-ASCII characters in the string returned by repr() using \verb|\x|, \verb|\u| or \verb|\U| escapes.

bin(x):
    Convert an integer number to a binary string. The result is a valid Python expression. If x is not a Python int object, it has to define an \_\_index\_\_() method that returns an integer.

\emph{class} bool([x]):
    Return a Boolean value, \emph{i.e.} one of \textbf{True} or \textbf{False}. $x$ is converted using the standard truth testing procedure. If x is false or omitted, this returns \textbf{False}; otherwise it returns \textbf{True}. The \emph{bool} class is a subclass of int (see Numeric Types — int, float, complex).

\emph{class} bytearray([source[, encoding[, errors]]]):
    Return a new array of bytes. The \emph{bytearray} class is a \textcolor{blue}{mutable} sequence of integers in the range $0 \leq x < 256$. It has most of the usual methods of mutable sequences, described in Mutable Sequence Types, as well as most methods that the bytes type has.

    The optional \emph{source} parameter can be used to initialize the array in a few different ways:
        If it is a string, you must also give the \emph{encoding} (and optionally, \emph{errors}) parameters; bytearray() then converts the string to bytes using str.encode().
        If it is an integer, the array will have that size and will be initialized with null bytes.
        If it is an object conforming to the buffer interface, a read-only buffer of the object will be used to initialize the bytes array.
        If it is an iterable, it must be an iterable of integers in the range $0 \leq x < 256$, which are used as the initial contents of the array.
    Without an argument, an array of size 0 is created.

\emph{class} bytes([source[, encoding[, errors]]]):
    Return a new ``bytes” object, which is an \textcolor{blue}{immutable} sequence of integers in the range $0 \leq x < 256$. bytes is an immutable version of bytearray –- it has the same non-mutating methods and the same indexing and slicing behavior.
    Accordingly, constructor arguments are interpreted as for bytearray().

callable(object):
    Return \textbf{True} if the object argument appears callable, \textbf{False} if not. If this returns true, it is still possible that a call fails, but if it is false, calling object will never succeed. Note that classes are callable (calling a class returns a new instance); instances are callable if their class has a \_\_call\_\_() method.

\colorbox{green}{chr(i)}:
    Return the string representing a character whose Unicode code point is the integer $i$. For example, chr(97) returns the string `a', while chr(8364) returns the string `€'. This is the inverse of ord().
    The valid range for the argument is from $0$ through $1,114,111$ (0x10FFFF in base 16). ValueError will be raised if i is outside that range.




\subsection{Most commonly used tricks}

data = np.ndarray(shape=(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS), dtype=np.float32)

# Note that data slicing by colon (:) and three dots (...)
validation_data = data[:validation_SIZE, ...]
train_data = data[validation_SIZE:, ...]

if not isinstance(ops, (list, tuple)):
    raise TypeError('ops must either be a list/tuple')

\textbf{\textcolor{red}{\url{http://jianfeihit.iteye.com/blog/1835272}}}


\section{Useful Modules}

\begin{python}

  import os

  os.path.join()
  os.environ["CUDA_VISIBLE_DEVICES"] = '1'
  if not os.path.exists(log_folder):
    os.makedirs(log_folder)

  os.rmdir(path) # remove/delete path
  os.chdir("target dir")
  os.listdir(folder_name)
  os.path.isdir('E:\\book\\temp')
  os.path.dirname()
  os.path.isfile('E:\\book\\temp')
  os.getcwd()# get current path
  os.sep
  os.walk(dir)

  os.path.splitext(fullpath)[1] == '.txt'

  for file in os.listdir("E:\\book"):
    if file.endswith(".mhd"):
        print(os.path.join("E:\\book", file))
  file.upper()

  os.path.basename(c).split('.')[0:1][0]
  os.path.split(filename)[0]

  #--------------------------------

  import fnmatch

  fnmatch.filter(os.listdir("/mydir"), "*.tx?")


  import glob

  glob.glob('./*.txt')

  #--------------------------------
  import re

  re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)


  #--------------------------------
  import tarfile


  #--------------------------------
  import sys

  sys.stdout.write("output path")
  sys.stdout.flush()
  sys.argv[0]

  sys.path.append("/home/dpakhom1/workspace/my_models/slim/")

  #--------------------------------
  import time

  time.sleep(1.0)

  start = time.time()
  elapsed = time.time() - start

  #--------------------------------
  import threading

  a = threading.Lock()
  a.release()


  #--------------------------------
  import math

  math.pi


  #--------------------------------
  import scipy

  scipy.ndimage.interpolation.zoom(img, real_resize)

  #--------------------------------
  import numpy as np

  np.frombuffer(buf, dtype=np.uint8).astype(np.float32)
  data = np.ndarray( shape=(num_images, Height, Width, num_CHANNELS), dtype=np.float32)
  np.zeros(shape=(num_images,), dtype=np.int64)
  np.sum(np.argmax(predictions, 1) == labels)

  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)
  labels = (np.arange(num_labels) == labels[:, None]).astype(np.float32)

  np.fromfile(f,dtype=np.uint16)
  np.asarray(trainY, dtype = bool)
  plt.grid(True)
  plt.yscale('symlog', linthreshy=0.01)

  np.round()
  np.random.normal()
  np.ogrid[:size, :size]
  np.random.randn(2, 10, 8)
  np.random.randint(0,1000,[1000,3])/1000.
  np.random.rand()
  np.random.seed(19680801)
  np.full()
  np.sum()
  np.equal()
  np.pi
  np.save(imageName + '_lung_img.npz', lung_img_512)

  t = np.arange(0.0, 5.0, 0.01)
  s = np.cos(2*np.pi*t)

  np.absolute(world_coordinates - origin)
  np.concatenate()
  x = np.asarray([[1,2,3],[4,5,6]])
  y = np.asarray([[7,8,9],[10,11,12]])
  p = np.stack((x, y), 2)
  q = np.concatenate((x[...,None], y[...,None]), axis=2)

  np.linalg.norm()


  #--------------------------------
  import pandas as pd

  train = pd.read_csv(tf.gfile.Open("./train.csv"),skipinitialspace=True)
  # Impute the missing ages with median age
  train["Age"] = train["Age"].fillna(train["Age"].median()).astype(int)
  # Write our changed dataframes to csv.
  train.to_csv('./train.csv', index=False)
  
  #--------------------------------
  import pickle
  
  pickle.dump()
  
  
  #--------------------------------  
  import xgboost as xgb
  
  
  
  import hyperopt as hp 
  hp.fmin()
  hp.tpe()
  hp.Trials()
  
  hp.hp()
  hp.hp.quniform()




  #--------------------------------
  import matplotlib.pyplot as plt

  plt.figure(figsize=(20,10))
  fig = plt.gcf()
  fig.set_size_inches(18.5, 10.5)
  fig.savefig('test2png.png', dpi=100)

  plt.hist(x, 50, normed=1, facecolor='g', alpha=0.75)
  plt.title(r'$\sigma_i=15$')
  plt.text(60, .025, r'$\mu=100,\ \sigma=15$')
  plt.xlabel('my data', fontsize=14, color='red')

  plt.subplots() is a function that returns a \textbf{tuple} containing a figure and axes object(s).
  fig, ax = plt.subplots() #unpack this tuple into the variables fig and ax object.
  ax[0].axis('off')
  ax[0].imshow(image, cmap=plt.cm.bone)
  cmap=plt.cm.bone

  plt.ylim(-2,2)
  plt.annotate('text', xy=(2, 1), xytext=(3, 1.5),arrowprops=
                        dict(facecolor='black', shrink=0.05),)

  #set the size of figure
  fig_size = [15, 4]
  plt.rcParams["figure.figsize"] = fig_size

  plt.ion()
  plt.ioff()
  plt.show()

  plt.plot()
  plt.scatter()

  #--------------------------------
  from PIL import Image

  #--------------------------------
  import dicom
  plan = dicom.read_file("rtplan.dcm")
  plan.PatientName #'Last^First^mid^pre'

  # get a list of tags with "setup" somewhere in the name
  plan.dir("setup")

  plan.PatientSetupSequence[0]

  plan.PatientSetupSequence[0].PatientPosition = "HFP"
  plan.save_as("rtplan2.dcm")

  #--------------------------------
  import argparse

  parser = argparse.ArgumentParser()
  parser.add_argument(
      '--use_fp16',
      default=False,
      help='Use half floats instead of full floats if True.',
      action='store_true')
  parser.parse_known_args()

  #--------------------------------
  import gzip
  bytestream = gzip.open(filename).read(16)
  buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)

  #--------------------------------

  from six.moves import urllib

  import functools
  import six




  #--------------------------------
  import tensorflow as tf

  sess = tf.Session()
  sess.run(optimizer, feed_dict=feed_dict)

  with tf.Session() as sess:
    tf.global_variables_initializer().run()

  if not tf.gfile.Exists(WORK_DIRECTORY):
    tf.gfile.MakeDirs(WORK_DIRECTORY)

  tf.gfile.GFile(filepath).size()
  tf.gfile.Open("./train.csv")

  tf.placeholder(data_type(), shape=(BATCH_SIZE, Width, Height, NUM_CHANNELS))

  tf.truncated_normal([5, 5, NUM_CHANNELS, 32], stddev=0.1, seed=SEED, dtype=tf.float32)# 5x5 filter, depth 32.
  tf.truncated_normal([image_size * image_size, hidden_node_count])
  tf.random_normal(shape, stddev=0.01)


  tf.Variable(tf.zeros([32], dtype=tf.float16))
  tf.Variable(tf.constant(0.1, shape=[64], dtype=tf.float16))
  conv = tf.nn.conv2d(data, conv_weights, strides=[1, 1, 1, 1], padding='SAME') # {strides} is a 4D array: [image_index, y, x, depth].
  relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))
  pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
  tf.reshape(pool, [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])
  hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)
  hidden = tf.nn.sigmoid(tf.matmul(X, w_h))

  hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)
  loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits( labels=train_labels_node, logits=logits))
  cost = tf.reduce_mean(tf.square(tf.squeeze(y) - y_))
  # L2 regularization for the fully connected parameters.
  regular = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) + tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))
  # Add the regularization term to the loss.
  loss += 5e-4 * regular

  learning_rate = tf.train.exponential_decay(
      0.01,                # Base learning rate.
      batch * BATCH_SIZE,  # Current index into the dataset.
      train_size,          # Decay step.
      0.95,                # Decay rate.
      staircase=True)
  # Use simple momentum for the optimization.
  optimizer = tf.train.MomentumOptimizer(learning_rate,0.9).minimize(loss, global_step=batch)
  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

  # Predictions for the current training minibatch.
  train_prediction = tf.nn.softmax(logits)

  # Predictions for the test and validation, which we'll compute less often.
  eval_prediction = tf.nn.softmax(model(eval_data))
  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)

  if __name__ == "__main__":
    tf.app.run()


  saver = tf.train.Saver()
  saver.save(sess, FLAGS.train_dir, global_step=step)
  saver.restore(sess, FLAGS.train_dir)

  sex = tf.contrib.layers.sparse_column_with_keys(column_name="Sex", keys=["female", "male"])
  name = tf.contrib.layers.sparse_column_with_hash_bucket("Name", hash_bucket_size=1000)
  age = tf.contrib.layers.real_valued_column("Age")

  tf.add(1, 2) # 3
  tf.sub(2, 1) # 1
  tf.mul(2, 2) # 4
  tf.multiply()
  tf.div(2, 2) # 1
  tf.mod(4, 5) # 4
  tf.pow(3, 2) # 9
  tf.less(1, 2) # x < y: True
  tf.equal()
  tf.not_equal()
  tf.less_equal()
  tf.greater()
  tf.greater_equal()
  tf.logical_and()
  tf.logical_or()
  tf.logical_xor()

  tf.SparseTensor()
  tf.SparseTensor(values=['IT', 'US', 'GB'],
                  indices=[[0, 0], [1, 3], [2, 1]],
                  shape=[3, 5]),

  cell = tf.nn.rnn_cell.LSTMCell(num_units=64, state_is_tuple=True)
  cell = tf.nn.rnn_cell.DropoutWrapper(cell=cell, output_keep_prob=0.5)
  cell = tf.nn.rnn_cell.MultiRNNCell(cells=[cell] * 4, state_is_tuple=True)
  outputs, last_states = tf.nn.dynamic_rnn(cell=cell, dtype=tf.float64, sequence_length=X_lengths, inputs=X)
  result = tf.contrib.learn.run_n({"outputs": outputs, "last_states": last_states}, n=1, feed_dict=None)

  svm_classifier = tf.contrib.learn.SVM(feature_columns=[price, sq_footage_bucket, country, sq_footage_country],
        example_id_column='example_id',
        weight_column_name='weights',
        l1_regularization=0.1,
        l2_regularization=1.0)

  weights = tf.get_variable("w", [1, 2])

  tf.dynamic_stitch()
  tf.dynamic_partition()

  tf.set_random_seed(1)

  tf.batch_matmul()

  with tf.name_scope('conv1') as scope:


  conv = tf.nn.conv2d(data, filter, strides=[1, 1, 1, 1], padding='SAME')
  # Given an input tensor of shape [batch, in_height, in_width, in_channels]
  # and a filter tensor of shape [filter_height, filter_width, in_channels, out_channels],
  # this op performs the following:
    1,Flattens the filter to a 2-D matrix with shape
      [filter_height * filter_width * in_channels, output_channels].
    2,Extracts image patches from the input tensor to form a virtual tensor of shape
      [batch, out_height, out_width, filter_height * filter_width * in_channels].
    3,For each patch, right-multiplies the filter matrix and the image patch vector.
    4,Must have strides[0] = strides[3] = 1. For the most common case of the same
      horizontal and vertices strides, strides = [1, stride, stride, 1].

  tf.expand_dims()
  tf.pack()

  tf.device('/cpu:0'):
  tf.cast(images, tf.float16)

  tf.read_file()

  tf.image.decode_jpeg(image_tensor, channels=3)
  tf.image.decode_png(annotation_tensor, channels=1)

  tf.nn.conv2d_transpose()

  tf.reshape()


  rank_assertion = tf.Assert( tf.equal(tf.rank(image), 3), ['Rank of image must be equal to 3.'])
  tf.logical_and( tf.greater_equal(1,2), ['one greater than two.']

  tf.convert_to_tensor(smallest_side, dtype=tf.int32)

\end{python}


















\end{document}
